#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
é‡‡é›†æœåŠ¡ - ä¸“é—¨è´Ÿè´£Telegramé‡‡é›†ä»»åŠ¡
"""

import os
import sys
import json
import time
import signal
import argparse
import asyncio
import logging
from datetime import datetime
from flask import Flask, request, jsonify
from typing import Dict, Any

# è®¾ç½®æ—¥å¿—æ ¼å¼
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)

# åˆ›å»ºlogger
logger = logging.getLogger('scraper')

app = Flask(__name__)

class ScraperService:
    """é‡‡é›†æœåŠ¡"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.pid = os.getpid()
        self.start_time = datetime.now()
        self.is_scraping = False
        self.last_scrape_time = None
        self.scrape_count = 0
        
        # å¯¼å…¥é‡‡é›†ç›¸å…³æ¨¡å—
        try:
            from scrape import (
                init_mysql_pool, close_mysql_pool, 
                scrape_channel, get_config_from_db
            )
            self.scrape_module = sys.modules['scrape']
            logger.info("âœ… é‡‡é›†æ¨¡å—å¯¼å…¥æˆåŠŸ")
        except ImportError as e:
            logger.error(f"âŒ é‡‡é›†æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
            self.scrape_module = None
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡çŠ¶æ€"""
        uptime = str(datetime.now() - self.start_time).split('.')[0]
        
        return {
            'success': True,
            'data': {
                'status': 'running',
                'pid': self.pid,
                'uptime': uptime,
                'start_time': self.start_time.strftime('%Y-%m-%d %H:%M:%S'),
                'is_scraping': self.is_scraping,
                'last_scrape_time': self.last_scrape_time.strftime('%Y-%m-%d %H:%M:%S') if self.last_scrape_time else None,
                'scrape_count': self.scrape_count,
                'port': self.config.get('port', '5002')
            }
        }
    
    def get_config(self) -> Dict[str, Any]:
        """è·å–é…ç½®ä¿¡æ¯"""
        return {
            'success': True,
            'data': {
                'api_id': self.config.get('api_id', ''),
                'api_hash': self.config.get('api_hash', ''),
                'phone_number': self.config.get('phone_number', ''),
                'mysql_host': self.config.get('mysql_host', ''),
                'mysql_database': self.config.get('mysql_database', ''),
                'mysql_user': self.config.get('mysql_user', ''),
                'mysql_password': '***',  # éšè—å¯†ç 
                'port': self.config.get('port', '5002')
            }
        }
    
    async def start_scraping(self) -> Dict[str, Any]:
        """å¼€å§‹é‡‡é›†ä»»åŠ¡"""
        try:
            if self.is_scraping:
                return {
                    'success': False,
                    'message': 'é‡‡é›†ä»»åŠ¡å·²åœ¨è¿è¡Œä¸­'
                }
            
            if not self.scrape_module:
                return {
                    'success': False,
                    'message': 'é‡‡é›†æ¨¡å—æœªæ­£ç¡®åŠ è½½'
                }
            
            self.is_scraping = True
            logger.info("ğŸš€ å¼€å§‹é‡‡é›†ä»»åŠ¡...")
            
            # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
            await self.scrape_module.init_mysql_pool()
            
            # åˆå§‹åŒ–å¹¶ç™»å½• Telegram å®¢æˆ·ç«¯
            logger.info("ğŸ” åˆå§‹åŒ– Telegram å®¢æˆ·ç«¯...")
            await self.scrape_module.init_telegram_client()
            logger.info("âœ… Telegram å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            
            # æ‰§è¡Œé‡‡é›†ä»»åŠ¡
            await self.scrape_module.scrape_channel()
            
            self.last_scrape_time = datetime.now()
            self.scrape_count += 1
            
            # å¯åŠ¨å®šæ—¶é‡‡é›†ä»»åŠ¡
            logger.info("ğŸ”„ å¯åŠ¨å®šæ—¶é‡‡é›†ä»»åŠ¡...")
            await self.scrape_module.run_periodic_scraper()
            
            logger.info("âœ… é‡‡é›†ä»»åŠ¡å®Œæˆ")
            
            return {
                'success': True,
                'message': 'é‡‡é›†ä»»åŠ¡å®Œæˆ',
                'scrape_time': self.last_scrape_time.strftime('%Y-%m-%d %H:%M:%S'),
                'scrape_count': self.scrape_count
            }
            
        except Exception as e:
            logger.error(f"âŒ é‡‡é›†ä»»åŠ¡å¤±è´¥: {e}")
            return {
                'success': False,
                'message': f'é‡‡é›†ä»»åŠ¡å¤±è´¥: {str(e)}'
            }
        finally:
            self.is_scraping = False
    
    async def init_telegram_only(self) -> Dict[str, Any]:
        """åˆå§‹åŒ–Telegramå®¢æˆ·ç«¯å¹¶è‡ªåŠ¨å¼€å§‹é‡‡é›†ä»»åŠ¡"""
        try:
            if not self.scrape_module:
                return {
                    'success': False,
                    'message': 'é‡‡é›†æ¨¡å—æœªæ­£ç¡®åŠ è½½'
                }
            
            logger.info("ğŸ” å¼€å§‹åˆå§‹åŒ–Telegramå®¢æˆ·ç«¯...")
            
            # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
            await self.scrape_module.init_mysql_pool()
            
            # åˆå§‹åŒ–å¹¶ç™»å½• Telegram å®¢æˆ·ç«¯
            await self.scrape_module.init_telegram_client()
            logger.info("âœ… Telegram å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–å®Œæˆåè‡ªåŠ¨å¼€å§‹é‡‡é›†ä»»åŠ¡
            logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œé‡‡é›†ä»»åŠ¡...")
            await self.scrape_module.scrape_channel()
            
            # å¯åŠ¨å®šæ—¶é‡‡é›†ä»»åŠ¡
            logger.info("ğŸ”„ å¯åŠ¨å®šæ—¶é‡‡é›†ä»»åŠ¡...")
            await self.scrape_module.run_periodic_scraper()
            
            self.last_scrape_time = datetime.now()
            self.scrape_count += 1
            
            logger.info("âœ… é‡‡é›†ä»»åŠ¡å®Œæˆ")
            
            return {
                'success': True,
                'message': 'Telegramå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œé‡‡é›†ä»»åŠ¡å·²å¼€å§‹',
                'scrape_time': self.last_scrape_time.strftime('%Y-%m-%d %H:%M:%S'),
                'scrape_count': self.scrape_count
            }
            
        except Exception as e:
            logger.error(f"âŒ Telegramå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            return {
                'success': False,
                'message': f'Telegramå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}'
            }

    def stop_scraping(self) -> Dict[str, Any]:
        """åœæ­¢é‡‡é›†ä»»åŠ¡"""
        try:
            if not self.is_scraping:
                return {
                    'success': False,
                    'message': 'é‡‡é›†ä»»åŠ¡æœªè¿è¡Œ'
                }
            
            self.is_scraping = False
            logger.info("ğŸ›‘ é‡‡é›†ä»»åŠ¡å·²åœæ­¢")
            
            return {
                'success': True,
                'message': 'é‡‡é›†ä»»åŠ¡å·²åœæ­¢'
            }
            
        except Exception as e:
            logger.error(f"âŒ åœæ­¢é‡‡é›†ä»»åŠ¡å¤±è´¥: {e}")
            return {
                'success': False,
                'message': f'åœæ­¢é‡‡é›†ä»»åŠ¡å¤±è´¥: {str(e)}'
            }

# å…¨å±€é‡‡é›†æœåŠ¡å®ä¾‹
scraper_service = None

@app.route('/api/scraper/status', methods=['GET'])
def handle_status():
    """å¤„ç†çŠ¶æ€æŸ¥è¯¢"""
    if not scraper_service:
        return jsonify({
            'success': False,
            'message': 'é‡‡é›†æœåŠ¡æœªåˆå§‹åŒ–'
        })
    
    return jsonify(scraper_service.get_status())

@app.route('/api/scraper/config', methods=['GET'])
def handle_config():
    """å¤„ç†é…ç½®æŸ¥è¯¢"""
    if not scraper_service:
        return jsonify({
            'success': False,
            'message': 'é‡‡é›†æœåŠ¡æœªåˆå§‹åŒ–'
        })
    
    return jsonify(scraper_service.get_config())

@app.route('/api/telegram/init', methods=['POST'])
def handle_telegram_init():
    """å¤„ç†Telegramå®¢æˆ·ç«¯åˆå§‹åŒ–è¯·æ±‚"""
    logger.info("ğŸ” æ”¶åˆ°Telegramå®¢æˆ·ç«¯åˆå§‹åŒ–è¯·æ±‚")
    
    if not scraper_service:
        logger.error("âŒ é‡‡é›†æœåŠ¡æœªåˆå§‹åŒ–")
        return jsonify({
            'success': False,
            'message': 'é‡‡é›†æœåŠ¡æœªåˆå§‹åŒ–'
        })
    
    # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œå¼‚æ­¥Telegramåˆå§‹åŒ–
    import threading
    
    def run_telegram_init():
        logger.info("ğŸ”„ Telegramåˆå§‹åŒ–çº¿ç¨‹å¯åŠ¨")
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            logger.info("â³ å¼€å§‹åˆå§‹åŒ–Telegramå®¢æˆ·ç«¯...")
            # åªåˆå§‹åŒ–Telegramå®¢æˆ·ç«¯ï¼Œä¸æ‰§è¡Œé‡‡é›†ä»»åŠ¡
            result = loop.run_until_complete(scraper_service.init_telegram_only())
            logger.info(f"âœ… Telegramåˆå§‹åŒ–ç»“æœ: {result}")
        except Exception as e:
            logger.error(f"âŒ Telegramåˆå§‹åŒ–å¼‚å¸¸: {e}")
            import traceback
            logger.error(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
        finally:
            # å®‰å…¨å…³é—­äº‹ä»¶å¾ªç¯
            try:
                # å–æ¶ˆæ‰€æœ‰å¾…å¤„ç†çš„ä»»åŠ¡
                pending = asyncio.all_tasks(loop)
                for task in pending:
                    task.cancel()
                
                # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
                if pending:
                    loop.run_until_complete(asyncio.gather(*pending, return_exceptions=True))
                
                loop.close()
                logger.info("ğŸ”„ Telegramåˆå§‹åŒ–çº¿ç¨‹ç»“æŸ")
            except Exception as cleanup_error:
                logger.error(f"âŒ æ¸…ç†äº‹ä»¶å¾ªç¯æ—¶å‡ºé”™: {cleanup_error}")
                try:
                    loop.close()
                except:
                    pass
    
    thread = threading.Thread(target=run_telegram_init)
    thread.daemon = True
    thread.start()
    
    return jsonify({
        'success': True,
        'message': 'Telegramå®¢æˆ·ç«¯åˆå§‹åŒ–å·²å¯åŠ¨ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—äº†è§£è¿›åº¦'
    })

@app.route('/api/scraper/start', methods=['POST'])
def handle_start_scraping():
    """å¤„ç†é‡‡é›†ä»»åŠ¡å¯åŠ¨"""
    logger.info("ğŸ¯ æ”¶åˆ°å¯åŠ¨é‡‡é›†ä»»åŠ¡è¯·æ±‚")
    
    if not scraper_service:
        logger.error("âŒ é‡‡é›†æœåŠ¡æœªåˆå§‹åŒ–")
        return jsonify({
            'success': False,
            'message': 'é‡‡é›†æœåŠ¡æœªåˆå§‹åŒ–'
        })
    
    logger.info("âœ… é‡‡é›†æœåŠ¡å·²åˆå§‹åŒ–ï¼Œå‡†å¤‡å¯åŠ¨é‡‡é›†ä»»åŠ¡")
    
    # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œå¼‚æ­¥é‡‡é›†ä»»åŠ¡
    import threading
    
    def run_scraping():
        logger.info("ğŸ”„ é‡‡é›†çº¿ç¨‹å¯åŠ¨")
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            logger.info("â³ å¼€å§‹æ‰§è¡Œé‡‡é›†ä»»åŠ¡...")
            result = loop.run_until_complete(scraper_service.start_scraping())
            logger.info(f"âœ… é‡‡é›†ä»»åŠ¡ç»“æœ: {result}")
        except Exception as e:
            logger.error(f"âŒ é‡‡é›†ä»»åŠ¡å¼‚å¸¸: {e}")
            import traceback
            logger.error(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
        finally:
            # å®‰å…¨å…³é—­äº‹ä»¶å¾ªç¯
            try:
                # å–æ¶ˆæ‰€æœ‰å¾…å¤„ç†çš„ä»»åŠ¡
                pending = asyncio.all_tasks(loop)
                for task in pending:
                    task.cancel()
                
                # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
                if pending:
                    loop.run_until_complete(asyncio.gather(*pending, return_exceptions=True))
                
                loop.close()
                logger.info("ğŸ”„ é‡‡é›†çº¿ç¨‹ç»“æŸ")
            except Exception as cleanup_error:
                logger.error(f"âŒ æ¸…ç†äº‹ä»¶å¾ªç¯æ—¶å‡ºé”™: {cleanup_error}")
                try:
                    loop.close()
                except:
                    pass
    
    thread = threading.Thread(target=run_scraping)
    thread.daemon = True
    thread.start()
    
    logger.info("âœ… é‡‡é›†ä»»åŠ¡å·²åœ¨åå°çº¿ç¨‹å¯åŠ¨")
    
    return jsonify({
        'success': True,
        'message': 'é‡‡é›†ä»»åŠ¡å·²å¯åŠ¨ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—äº†è§£è¿›åº¦'
    })

@app.route('/api/scraper/stop', methods=['POST'])
def handle_stop_scraping():
    """å¤„ç†é‡‡é›†ä»»åŠ¡åœæ­¢"""
    if not scraper_service:
        return jsonify({
            'success': False,
            'message': 'é‡‡é›†æœåŠ¡æœªåˆå§‹åŒ–'
        })
    
    return jsonify(scraper_service.stop_scraping())

@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        'status': 'healthy',
        'service': 'tg2em-scraper',
        'timestamp': datetime.now().isoformat(),
        'pid': os.getpid()
    })

@app.route('/')
def index():
    """æœåŠ¡ä¿¡æ¯é¡µé¢"""
    if not scraper_service:
        return jsonify({
            'success': False,
            'message': 'é‡‡é›†æœåŠ¡æœªåˆå§‹åŒ–'
        })
    
    status = scraper_service.get_status()
    config = scraper_service.get_config()
    
    return f'''
    <!DOCTYPE html>
    <html lang="zh-CN">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>tg2em é‡‡é›†æœåŠ¡</title>
        <style>
            body {{ font-family: Arial, sans-serif; margin: 40px; background: #f5f5f5; }}
            .container {{ max-width: 800px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
            .status {{ padding: 15px; margin: 10px 0; border-radius: 5px; background: #d4edda; border: 1px solid #c3e6cb; color: #155724; }}
            .info {{ background: #f8f9fa; padding: 15px; margin: 10px 0; border-radius: 5px; }}
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸ”„ tg2em é‡‡é›†æœåŠ¡</h1>
            <div class="status">
                <strong>æœåŠ¡çŠ¶æ€:</strong> è¿è¡Œä¸­<br>
                <strong>PID:</strong> {status['data']['pid']}<br>
                <strong>è¿è¡Œæ—¶é—´:</strong> {status['data']['uptime']}<br>
                <strong>é‡‡é›†çŠ¶æ€:</strong> {'è¿è¡Œä¸­' if status['data']['is_scraping'] else 'ç©ºé—²'}<br>
                <strong>é‡‡é›†æ¬¡æ•°:</strong> {status['data']['scrape_count']}
            </div>
            <div class="info">
                <h3>æœåŠ¡ä¿¡æ¯</h3>
                <p><strong>æœåŠ¡åç§°:</strong> tg2em Scraper Service</p>
                <p><strong>ç‰ˆæœ¬:</strong> 2.0.0</p>
                <p><strong>ç«¯å£:</strong> {config['data']['port']}</p>
                <p><strong>æ¶æ„:</strong> åŒæœåŠ¡æ¶æ„ - é‡‡é›†æœåŠ¡</p>
            </div>
        </div>
    </body>
    </html>
    '''

def signal_handler(signum, frame):
    """ä¿¡å·å¤„ç†å™¨"""
    logger.info("ğŸ›‘ é‡‡é›†æœåŠ¡æ­£åœ¨å…³é—­...")
    sys.exit(0)

def main():
    """ä¸»å‡½æ•°"""
    global scraper_service
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='tg2em é‡‡é›†æœåŠ¡')
    parser.add_argument('--api-id', default=os.getenv('API_ID', ''), help='Telegram API ID')
    parser.add_argument('--api-hash', default=os.getenv('API_HASH', ''), help='Telegram API Hash')
    parser.add_argument('--phone', default=os.getenv('PHONE_NUMBER', ''), help='Phone Number')
    parser.add_argument('--mysql-host', default=os.getenv('MYSQL_HOST', 'mysql'), help='MySQL Host')
    parser.add_argument('--mysql-database', default=os.getenv('MYSQL_DATABASE', 'tg2em'), help='MySQL Database')
    parser.add_argument('--mysql-user', default=os.getenv('MYSQL_USER', 'tg2emall'), help='MySQL User')
    parser.add_argument('--mysql-password', default=os.getenv('MYSQL_PASSWORD', 'tg2emall'), help='MySQL Password')
    parser.add_argument('--port', default=os.getenv('SCRAPER_PORT', '5002'), help='Service Port')
    
    args = parser.parse_args()
    
    # éªŒè¯å¿…éœ€é…ç½®
    if not args.api_id or not args.api_hash or not args.phone:
        logger.error("âŒ ç¼ºå°‘å¿…éœ€é…ç½®: API_ID, API_HASH, PHONE_NUMBER")
        sys.exit(1)
    
    # åˆ›å»ºé…ç½®
    config = {
        'api_id': args.api_id,
        'api_hash': args.api_hash,
        'phone_number': args.phone,
        'mysql_host': args.mysql_host,
        'mysql_database': args.mysql_database,
        'mysql_user': args.mysql_user,
        'mysql_password': args.mysql_password,
        'port': args.port
    }
    
    # åˆ›å»ºé‡‡é›†æœåŠ¡å®ä¾‹
    scraper_service = ScraperService(config)
    
    # æ³¨å†Œä¿¡å·å¤„ç†å™¨
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    logger.info("ğŸš€ tg2emé‡‡é›†æœåŠ¡å¯åŠ¨ä¸­...")
    logger.info(f"ğŸ“Š é‡‡é›†æœåŠ¡PID: {scraper_service.pid}")
    logger.info(f"ğŸ“¡ æœåŠ¡ç«¯å£: {config['port']}")
    logger.info(f"ğŸ“± Telegramé…ç½®: API_ID={args.api_id[:4]}***, Phone={args.phone}")
    
    # å¯åŠ¨Flaskåº”ç”¨
    app.run(host='0.0.0.0', port=int(config['port']), debug=False)

if __name__ == '__main__':
    main()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
é‡‡é›†æœåŠ¡ - ä¸“é—¨è´Ÿè´£Telegramé‡‡é›†ä»»åŠ¡
"""

import os
import sys
import json
import time
import signal
import argparse
import asyncio
import logging
from datetime import datetime
from flask import Flask, request, jsonify
from typing import Dict, Any

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('/app/logs/scraper-service.log')
    ]
)
logger = logging.getLogger(__name__)

app = Flask(__name__)

class ScraperService:
    """é‡‡é›†æœåŠ¡"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.pid = os.getpid()
        self.start_time = datetime.now()
        self.is_scraping = False
        self.last_scrape_time = None
        self.scrape_count = 0
        
        # å¯¼å…¥é‡‡é›†ç›¸å…³æ¨¡å—
        try:
            from scrape import (
                init_mysql_pool, close_mysql_pool, 
                scrape_channel, get_config_from_db
            )
            self.scrape_module = sys.modules['scrape']
            logger.info("âœ… é‡‡é›†æ¨¡å—å¯¼å…¥æˆåŠŸ")
        except ImportError as e:
            logger.error(f"âŒ é‡‡é›†æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
            self.scrape_module = None
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡çŠ¶æ€"""
        uptime = str(datetime.now() - self.start_time).split('.')[0]
        
        return {
            'success': True,
            'data': {
                'status': 'running',
                'pid': self.pid,
                'uptime': uptime,
                'start_time': self.start_time.strftime('%Y-%m-%d %H:%M:%S'),
                'is_scraping': self.is_scraping,
                'last_scrape_time': self.last_scrape_time.strftime('%Y-%m-%d %H:%M:%S') if self.last_scrape_time else None,
                'scrape_count': self.scrape_count,
                'port': self.config.get('port', '5002')
            }
        }
    
    def get_config(self) -> Dict[str, Any]:
        """è·å–é…ç½®ä¿¡æ¯"""
        return {
            'success': True,
            'data': {
                'api_id': self.config.get('api_id', ''),
                'api_hash': self.config.get('api_hash', ''),
                'phone_number': self.config.get('phone_number', ''),
                'mysql_host': self.config.get('mysql_host', ''),
                'mysql_database': self.config.get('mysql_database', ''),
                'mysql_user': self.config.get('mysql_user', ''),
                'mysql_password': '***',  # éšè—å¯†ç 
                'port': self.config.get('port', '5002')
            }
        }
    
    async def start_scraping(self) -> Dict[str, Any]:
        """å¼€å§‹é‡‡é›†ä»»åŠ¡"""
        try:
            if self.is_scraping:
                return {
                    'success': False,
                    'message': 'é‡‡é›†ä»»åŠ¡å·²åœ¨è¿è¡Œä¸­'
                }
            
            if not self.scrape_module:
                return {
                    'success': False,
                    'message': 'é‡‡é›†æ¨¡å—æœªæ­£ç¡®åŠ è½½'
                }
            
            self.is_scraping = True
            logger.info("ğŸš€ å¼€å§‹é‡‡é›†ä»»åŠ¡...")
            
            # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
            await self.scrape_module.init_mysql_pool()
            
            # åˆå§‹åŒ–å¹¶ç™»å½• Telegram å®¢æˆ·ç«¯
            logger.info("ğŸ” åˆå§‹åŒ– Telegram å®¢æˆ·ç«¯...")
            await self.scrape_module.init_telegram_client()
            logger.info("âœ… Telegram å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            
            # æ‰§è¡Œé‡‡é›†ä»»åŠ¡
            await self.scrape_module.scrape_channel()
            
            self.last_scrape_time = datetime.now()
            self.scrape_count += 1
            
            logger.info("âœ… é‡‡é›†ä»»åŠ¡å®Œæˆ")
            
            return {
                'success': True,
                'message': 'é‡‡é›†ä»»åŠ¡å®Œæˆ',
                'scrape_time': self.last_scrape_time.strftime('%Y-%m-%d %H:%M:%S'),
                'scrape_count': self.scrape_count
            }
            
        except Exception as e:
            logger.error(f"âŒ é‡‡é›†ä»»åŠ¡å¤±è´¥: {e}")
            return {
                'success': False,
                'message': f'é‡‡é›†ä»»åŠ¡å¤±è´¥: {str(e)}'
            }
        finally:
            self.is_scraping = False
    
    def stop_scraping(self) -> Dict[str, Any]:
        """åœæ­¢é‡‡é›†ä»»åŠ¡"""
        try:
            if not self.is_scraping:
                return {
                    'success': False,
                    'message': 'é‡‡é›†ä»»åŠ¡æœªè¿è¡Œ'
                }
            
            self.is_scraping = False
            logger.info("ğŸ›‘ é‡‡é›†ä»»åŠ¡å·²åœæ­¢")
            
            return {
                'success': True,
                'message': 'é‡‡é›†ä»»åŠ¡å·²åœæ­¢'
            }
            
        except Exception as e:
            logger.error(f"âŒ åœæ­¢é‡‡é›†ä»»åŠ¡å¤±è´¥: {e}")
            return {
                'success': False,
                'message': f'åœæ­¢é‡‡é›†ä»»åŠ¡å¤±è´¥: {str(e)}'
            }

# å…¨å±€é‡‡é›†æœåŠ¡å®ä¾‹
scraper_service = None

@app.route('/api/scraper/status', methods=['GET'])
def handle_status():
    """å¤„ç†çŠ¶æ€æŸ¥è¯¢"""
    if not scraper_service:
        return jsonify({
            'success': False,
            'message': 'é‡‡é›†æœåŠ¡æœªåˆå§‹åŒ–'
        })
    
    return jsonify(scraper_service.get_status())

@app.route('/api/scraper/config', methods=['GET'])
def handle_config():
    """å¤„ç†é…ç½®æŸ¥è¯¢"""
    if not scraper_service:
        return jsonify({
            'success': False,
            'message': 'é‡‡é›†æœåŠ¡æœªåˆå§‹åŒ–'
        })
    
    return jsonify(scraper_service.get_config())

@app.route('/api/scraper/start', methods=['POST'])
def handle_start_scraping():
    """å¤„ç†é‡‡é›†ä»»åŠ¡å¯åŠ¨"""
    if not scraper_service:
        return jsonify({
            'success': False,
            'message': 'é‡‡é›†æœåŠ¡æœªåˆå§‹åŒ–'
        })
    
    # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œå¼‚æ­¥é‡‡é›†ä»»åŠ¡
    import threading
    
    def run_scraping():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            result = loop.run_until_complete(scraper_service.start_scraping())
            logger.info(f"é‡‡é›†ä»»åŠ¡ç»“æœ: {result}")
        except Exception as e:
            logger.error(f"é‡‡é›†ä»»åŠ¡å¼‚å¸¸: {e}")
        finally:
            loop.close()
    
    thread = threading.Thread(target=run_scraping)
    thread.daemon = True
    thread.start()
    
    return jsonify({
        'success': True,
        'message': 'é‡‡é›†ä»»åŠ¡å·²å¯åŠ¨'
    })

@app.route('/api/scraper/stop', methods=['POST'])
def handle_stop_scraping():
    """å¤„ç†é‡‡é›†ä»»åŠ¡åœæ­¢"""
    if not scraper_service:
        return jsonify({
            'success': False,
            'message': 'é‡‡é›†æœåŠ¡æœªåˆå§‹åŒ–'
        })
    
    return jsonify(scraper_service.stop_scraping())

@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        'status': 'healthy',
        'service': 'tg2em-scraper',
        'timestamp': datetime.now().isoformat(),
        'pid': os.getpid()
    })

@app.route('/')
def index():
    """æœåŠ¡ä¿¡æ¯é¡µé¢"""
    if not scraper_service:
        return jsonify({
            'success': False,
            'message': 'é‡‡é›†æœåŠ¡æœªåˆå§‹åŒ–'
        })
    
    status = scraper_service.get_status()
    config = scraper_service.get_config()
    
    return f'''
    <!DOCTYPE html>
    <html lang="zh-CN">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>tg2em é‡‡é›†æœåŠ¡</title>
        <style>
            body {{ font-family: Arial, sans-serif; margin: 40px; background: #f5f5f5; }}
            .container {{ max-width: 800px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
            .status {{ padding: 15px; margin: 10px 0; border-radius: 5px; background: #d4edda; border: 1px solid #c3e6cb; color: #155724; }}
            .info {{ background: #f8f9fa; padding: 15px; margin: 10px 0; border-radius: 5px; }}
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸ”„ tg2em é‡‡é›†æœåŠ¡</h1>
            <div class="status">
                <strong>æœåŠ¡çŠ¶æ€:</strong> è¿è¡Œä¸­<br>
                <strong>PID:</strong> {status['data']['pid']}<br>
                <strong>è¿è¡Œæ—¶é—´:</strong> {status['data']['uptime']}<br>
                <strong>é‡‡é›†çŠ¶æ€:</strong> {'è¿è¡Œä¸­' if status['data']['is_scraping'] else 'ç©ºé—²'}<br>
                <strong>é‡‡é›†æ¬¡æ•°:</strong> {status['data']['scrape_count']}
            </div>
            <div class="info">
                <h3>æœåŠ¡ä¿¡æ¯</h3>
                <p><strong>æœåŠ¡åç§°:</strong> tg2em Scraper Service</p>
                <p><strong>ç‰ˆæœ¬:</strong> 2.0.0</p>
                <p><strong>ç«¯å£:</strong> {config['data']['port']}</p>
                <p><strong>æ¶æ„:</strong> åŒæœåŠ¡æ¶æ„ - é‡‡é›†æœåŠ¡</p>
            </div>
        </div>
    </body>
    </html>
    '''

def signal_handler(signum, frame):
    """ä¿¡å·å¤„ç†å™¨"""
    logger.info("ğŸ›‘ é‡‡é›†æœåŠ¡æ­£åœ¨å…³é—­...")
    sys.exit(0)

def main():
    """ä¸»å‡½æ•°"""
    global scraper_service
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='tg2em é‡‡é›†æœåŠ¡')
    parser.add_argument('--api-id', default=os.getenv('API_ID', ''), help='Telegram API ID')
    parser.add_argument('--api-hash', default=os.getenv('API_HASH', ''), help='Telegram API Hash')
    parser.add_argument('--phone', default=os.getenv('PHONE_NUMBER', ''), help='Phone Number')
    parser.add_argument('--mysql-host', default=os.getenv('MYSQL_HOST', 'mysql'), help='MySQL Host')
    parser.add_argument('--mysql-database', default=os.getenv('MYSQL_DATABASE', 'tg2em'), help='MySQL Database')
    parser.add_argument('--mysql-user', default=os.getenv('MYSQL_USER', 'tg2emall'), help='MySQL User')
    parser.add_argument('--mysql-password', default=os.getenv('MYSQL_PASSWORD', 'tg2emall'), help='MySQL Password')
    parser.add_argument('--port', default=os.getenv('SCRAPER_PORT', '5002'), help='Service Port')
    
    args = parser.parse_args()
    
    # éªŒè¯å¿…éœ€é…ç½®
    if not args.api_id or not args.api_hash or not args.phone:
        logger.error("âŒ ç¼ºå°‘å¿…éœ€é…ç½®: API_ID, API_HASH, PHONE_NUMBER")
        sys.exit(1)
    
    # åˆ›å»ºé…ç½®
    config = {
        'api_id': args.api_id,
        'api_hash': args.api_hash,
        'phone_number': args.phone,
        'mysql_host': args.mysql_host,
        'mysql_database': args.mysql_database,
        'mysql_user': args.mysql_user,
        'mysql_password': args.mysql_password,
        'port': args.port
    }
    
    # åˆ›å»ºé‡‡é›†æœåŠ¡å®ä¾‹
    scraper_service = ScraperService(config)
    
    # æ³¨å†Œä¿¡å·å¤„ç†å™¨
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    logger.info("ğŸš€ tg2emé‡‡é›†æœåŠ¡å¯åŠ¨ä¸­...")
    logger.info(f"ğŸ“Š é‡‡é›†æœåŠ¡PID: {scraper_service.pid}")
    logger.info(f"ğŸ“¡ æœåŠ¡ç«¯å£: {config['port']}")
    logger.info(f"ğŸ“± Telegramé…ç½®: API_ID={args.api_id[:4]}***, Phone={args.phone}")
    
    # å¯åŠ¨Flaskåº”ç”¨
    app.run(host='0.0.0.0', port=int(config['port']), debug=False)

if __name__ == '__main__':
    main()
